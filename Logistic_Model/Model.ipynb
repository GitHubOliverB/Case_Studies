{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic Python Libs - Not everything will be used here...\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import csv\n",
    "import pydotplus\n",
    "import plotly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, learning_curve\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Own Imports\n",
    "from Parameters import *\n",
    "from Classifier_Trainer import *\n",
    "from Classifier_Validation_Plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to train a model. Before I can do that I need to label and encode the categorial variables (Since categorial features are not supported in sklearn...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paths, functions and other useful stuff\n",
    "data_path = \"..\\\\Data\\\\\"\n",
    "file_name = \"challenge_data.csv\"\n",
    "\n",
    "classifier_path = classifier_name[0]\n",
    "if not os.path.exists(classifier_path):\n",
    "    os.makedirs(classifier_path)\n",
    "model_path = classifier_path+\"\\Model\\\\\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "plot_path = classifier_path+\"\\Plots\"\n",
    "if not os.path.exists(plot_path):\n",
    "    os.makedirs(plot_path)\n",
    "tree_path = plot_path+\"\\Decision_Trees\\\\\"\n",
    "if not os.path.exists(tree_path):\n",
    "    os.makedirs(tree_path)\n",
    "correlation_path = plot_path+\"\\Correlations\"\n",
    "if not os.path.exists(correlation_path):\n",
    "    os.makedirs(correlation_path)\n",
    "training_path = plot_path+\"\\Training\\\\\"\n",
    "if not os.path.exists(training_path):\n",
    "    os.makedirs(training_path)\n",
    "validation_path = plot_path+\"\\Validation\\\\\"\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "visualization_path = plot_path+\"\\Visualization\\\\\"\n",
    "if not os.path.exists(visualization_path):\n",
    "    os.makedirs(visualization_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'height_in_cm', 'date_shipped', 'size', 'itret',\n",
      "       'shipping_country', 'weight_in_kg', 'price', 'category_Belts',\n",
      "       'category_Blazers',\n",
      "       ...\n",
      "       'brand_Brand76', 'brand_Brand77', 'brand_Brand78', 'brand_Brand79',\n",
      "       'brand_Brand8', 'brand_Brand80', 'brand_Brand81', 'brand_Brand82',\n",
      "       'brand_Brand83', 'brand_Brand9'],\n",
      "      dtype='object', length=171)\n"
     ]
    }
   ],
   "source": [
    "# Data import and dummy variables\n",
    "df = pd.read_csv(data_path+file_name, delimiter=',')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "cat_cols = ['category', 'product_group', 'color', 'brand']\n",
    "df_dummies = pd.get_dummies(df, prefix_sep=\"_\",\n",
    "                              columns=cat_cols)\n",
    "\n",
    "size_values = ['S', 'M', 'L', 'XL', 'XXL']\n",
    "size_label = ['0', '1', '2', '3', '4']\n",
    "df_dummies = df_dummies.replace(to_replace=size_values, value=size_label)\n",
    "print(df_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our dummy variables and we labled our size feature accordingly.\n",
    "In order to train our model, we will need to split our dataset into at least one training and one testing sample. I would invest more time in a better splitting, but given the timeframe I'll settle with a very simple splitting.\n",
    "Next up we define our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reserving 5.00% Of Events For Later Use: 7,344\n",
      "\n",
      "Using 95.00% Of Events For Splitting: 139,522\n",
      "\n",
      "Using 47.50% Of Events For Training: 69,761\n",
      "\n",
      "Using 47.50% Of Events For Testing: 69,761\n",
      "\n",
      "Data Has Been Split...\n"
     ]
    }
   ],
   "source": [
    "#Feature_List = df_dummies.columns.tolist()\n",
    "#Feature_List.remove('itret')\n",
    "#Feature_List.remove('date_shipped')\n",
    "#print(Feature_List)\n",
    "\n",
    "X = df_dummies[Feature_List] # Indepent variables\n",
    "y = df_dummies['itret'] # Dependent Variables\n",
    "\n",
    "# Split\n",
    "X_dev, X_eval, y_dev, y_eval = train_test_split(X, y, test_size=reserve_fraction, random_state=42)\n",
    "print(\"\\nReserving \" + str(format(reserve_fraction*100, '.2f')) + \"% Of Events For Later Use: \" + str(format(len(X_eval), ',.0f')))\n",
    "print(\"\\nUsing \" + str(format((1-reserve_fraction)*100, '.2f')) + \"% Of Events For Splitting: \" + str(format(len(X_dev), ',.0f')))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=test_fraction, random_state=random_seeds[0])\n",
    "print(\"\\nUsing \" + str(format((1-reserve_fraction)*(1-test_fraction)*100, '.2f')) + \"% Of Events For Training: \" + str(format(len(X_train), ',.0f')))\n",
    "print(\"\\nUsing \" + str(format((1-reserve_fraction)*test_fraction*100, '.2f')) + \"% Of Events For Testing: \" + str(format(len(X_test), ',.0f')))\n",
    "print(\"\\nData Has Been Split...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     \"loss\":[\"deviance\"],\n",
    "#     \"min_samples_leaf\": np.linspace(0.05, 0.2, 4),\n",
    "#     \"max_depth\": range(2,6),\n",
    "#     \"criterion\": [\"friedman_mse\"],\n",
    "#     \"subsample\":[0.8, 0.9, 1.0],\n",
    "#     \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "#     \"n_estimators\": np.arange(50, 300, 50)\n",
    "#     }\n",
    "\n",
    "\n",
    "# # run randomized search\n",
    "# print(\"Defining the Gridsearch\")\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), parameters, scoring='roc_auc', cv=3, n_jobs=4, verbose=2)\n",
    "# print(\"Training on all gridpoints...\")\n",
    "# clf.fit(X_train, y_train)\n",
    "# print('Gradient boosting trees best params:', clf.best_params_)\n",
    "# print('Gradient boosting trees score:', clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model, train it and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24391 10472]\n",
      " [11507 23391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.68      0.70      0.69     34863\n",
      "      signal       0.69      0.67      0.68     34898\n",
      "\n",
      "    accuracy                           0.68     69761\n",
      "   macro avg       0.69      0.68      0.68     69761\n",
      "weighted avg       0.69      0.68      0.68     69761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GB_clfs = {}\n",
    "# GB_clfs[str(classifier_name[0])] = GradientBoostingClassifier(max_depth=max_depth, \n",
    "#                                                               min_samples_leaf=min_samples_leaf, \n",
    "#                                                               random_state=0, subsample=subsample, \n",
    "#                                                               n_estimators=n_estimators, \n",
    "#                                                               learning_rate=learning_rate, \n",
    "#                                                               verbose=True)\n",
    "# clfs=[]\n",
    "# print(\"\\nCrosstraining - 0\")\n",
    "# classifier_training(X_train, y_train, X_test, y_test, clfs, 0, \n",
    "#                     GB_clfs[classifier_name[0]], model_path, tree_path, training_path, False)\n",
    "# print(\"---\"*42)\n",
    "# print(\"Crosstraining - 1\")\n",
    "# classifier_training(X_train, y_train, X_test, y_test,clfs,  1, \n",
    "#                     GB_clfs[classifier_name[0]], model_path, tree_path, training_path, False)\n",
    "# print(\"\\nFinished Training...\")\n",
    "# print(\"---\"*42)\n",
    "# clfs[0].set_params(verbose=False)\n",
    "# clfs[1].set_params(verbose=False)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'liblinear', max_iter = 5000)\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "score = logisticRegr.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, target_names=[\"background\", \"signal\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b4d6f878ab74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNtree_ROC_Curve_Figname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_Tree_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_ROC.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_Ntree_ROC_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNtree_ROC_Curve_Figname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mNtree_PR_Curve_Figname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_Tree_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_PR.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_Ntree_PR_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNtree_PR_Curve_Figname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clfs' is not defined"
     ]
    }
   ],
   "source": [
    "Ntree_ROC_Curve_Figname = validation_path + str(classifier_name[0]) + \"_Tree_\" + str(len(clfs[0].estimators_)) + \"_ROC.png\"\n",
    "plot_Ntree_ROC_curve(clfs[0], (X_train,y_train),(X_test,y_test), Ntree_ROC_Curve_Figname)\n",
    "Ntree_PR_Curve_Figname = validation_path + str(classifier_name[0]) + \"_Tree_\" + str(len(clfs[0].estimators_)) + \"_PR.png\"\n",
    "plot_Ntree_PR_curve(clfs[0], (X_train,y_train),(X_test,y_test), Ntree_PR_Curve_Figname)\n",
    "\n",
    "# Reference For Some Of These Numbers\n",
    "# P - condition positive, the number of real positive cases in the data\n",
    "# N - condition negative, the number of real negative cases in the data\n",
    "\n",
    "# TP - true positive, eqv. with hit\n",
    "\n",
    "# TN - true negative,  eqv. with correct rejection\n",
    "# FP - false positive, eqv. with false alarm, Type I error\n",
    "# FN - false negative,  eqv. with miss, Type II error\n",
    "\n",
    "# PPV - Precision = TP / (TP + FP) = 1 - FDR, positive predictive value\n",
    "# TPR - Recall = TP / (TP + FN) = 1 - FNR, true positive rate\n",
    "# FNR - Miss Rate = FN / (FN + TP) = 1 - TPR, false negative rate\n",
    "# FDR - False Discovery Rate = FP / (FP + TP)\n",
    "# ACC - Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# F betta - F betta Score = (1+ betta**2) * ( PPV * TPR) / (betta**2 * PPV + TPR), is the harmonic mean of precision and recall\n",
    "\n",
    "# If I ever want to plot multiple clfs\n",
    "#fig, axes = plt.subplots(nrows=len(clfs), sharex=True)\n",
    "#for clf, ax in zip(clfs, axes):  \n",
    "#\tplot_learning_curve(clf, \"Learning curves\", X_dev, y_dev, scoring='roc_auc', n_jobs=7, cv=4, ax=ax, xlabel=False)\n",
    "#axes[0].legend(loc=\"best\")\n",
    "#axes[-1].set_xlabel(\"Training examples\")\n",
    "\n",
    "print(\"Plotting Performance vs. Size Of Training Set...\")\n",
    "fig, axis = plt.subplots(nrows=1, sharex=True)\n",
    "plot_learning_curve(clfs[0], \"Learning curves\", X_dev, y_dev, n_jobs=n_jobs, cv=cv, ax=axis)\n",
    "axis.legend(loc=\"best\")\n",
    "axis.set_xlabel(\"Training examples\")\n",
    "fig_name = validation_path + str(classifier_name[0]) + \"_Score_Validation\" + \".png\"\n",
    "plt.savefig(fig_name)\n",
    "plt.close()\n",
    "print(\"\\nFinished Validation...\")\n",
    "print(\"---\"*42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
